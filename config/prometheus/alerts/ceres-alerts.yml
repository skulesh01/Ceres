groups:
  # ==========================================
  # Infrastructure Alerts
  # ==========================================
  - name: infrastructure
    interval: 30s
    rules:
      # Instance down
      - alert: InstanceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Instance {{ $labels.instance }} down"
          description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute."

      # High CPU usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% (current: {{ $value }}%)"

      # High memory usage
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% (current: {{ $value }}%)"

      # Disk space low
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 15
        for: 5m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk space on / is below 15% (current: {{ $value }}%)"

      # Disk will fill in 4 hours
      - alert: DiskWillFillSoon
        expr: predict_linear(node_filesystem_avail_bytes{mountpoint="/"}[1h], 4*3600) < 0
        for: 30m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Disk will fill in 4 hours on {{ $labels.instance }}"
          description: "Disk space is predicted to run out in 4 hours"

  # ==========================================
  # Database Alerts
  # ==========================================
  - name: database
    interval: 30s
    rules:
      # PostgreSQL down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          service: database
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance has been down for more than 1 minute"

      # Too many connections
      - alert: PostgreSQLTooManyConnections
        expr: sum(pg_stat_database_numbackends) / max(pg_settings_max_connections) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "PostgreSQL has too many connections"
          description: "{{ $value }}% of max connections are in use"

      # Replication lag
      - alert: PostgreSQLReplicationLag
        expr: pg_replication_lag > 30
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "PostgreSQL replication lag detected"
          description: "Replication lag is {{ $value }} seconds"

      # Redis down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          service: database
        annotations:
          summary: "Redis is down"
          description: "Redis instance has been down for more than 1 minute"

      # Redis memory usage high
      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Redis memory usage is high"
          description: "Redis is using {{ $value }}% of max memory"

  # ==========================================
  # Application Alerts
  # ==========================================
  - name: application
    interval: 30s
    rules:
      # GitLab down
      - alert: GitLabDown
        expr: up{job="gitlab"} == 0
        for: 2m
        labels:
          severity: critical
          service: application
        annotations:
          summary: "GitLab is down"
          description: "GitLab has been unreachable for 2 minutes"

      # Pipeline failure rate high
      - alert: GitLabHighPipelineFailureRate
        expr: (sum(rate(gitlab_ci_pipeline_status{status="failed"}[1h])) / sum(rate(gitlab_ci_pipeline_status[1h]))) * 100 > 20
        for: 15m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "High GitLab pipeline failure rate"
          description: "{{ $value }}% of pipelines are failing"

      # Nextcloud down
      - alert: NextcloudDown
        expr: up{job="nextcloud"} == 0
        for: 2m
        labels:
          severity: critical
          service: application
        annotations:
          summary: "Nextcloud is down"
          description: "Nextcloud has been unreachable for 2 minutes"

      # Nextcloud storage almost full
      - alert: NextcloudStorageAlmostFull
        expr: nextcloud_storage_used_bytes / nextcloud_storage_total_bytes * 100 > 90
        for: 10m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "Nextcloud storage almost full"
          description: "Nextcloud storage is {{ $value }}% full"

      # Zulip down
      - alert: ZulipDown
        expr: up{job="zulip"} == 0
        for: 2m
        labels:
          severity: critical
          service: application
        annotations:
          summary: "Zulip is down"
          description: "Zulip has been unreachable for 2 minutes"

  # ==========================================
  # Container Alerts
  # ==========================================
  - name: containers
    interval: 30s
    rules:
      # Container high memory
      - alert: ContainerHighMemory
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: containers
        annotations:
          summary: "Container {{ $labels.name }} high memory"
          description: "Container is using {{ $value }}% of memory limit"

      # Container high CPU
      - alert: ContainerHighCPU
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: containers
        annotations:
          summary: "Container {{ $labels.name }} high CPU"
          description: "Container CPU usage is {{ $value }}%"

      # Container restart loop
      - alert: ContainerRestartLoop
        expr: rate(container_last_seen[5m]) > 2
        for: 5m
        labels:
          severity: critical
          service: containers
        annotations:
          summary: "Container {{ $labels.name }} restarting frequently"
          description: "Container has restarted {{ $value }} times in 5 minutes"

  # ==========================================
  # Network Alerts
  # ==========================================
  - name: network
    interval: 30s
    rules:
      # High network errors
      - alert: HighNetworkErrors
        expr: rate(node_network_receive_errs_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          service: network
        annotations:
          summary: "High network errors on {{ $labels.instance }}"
          description: "{{ $value }} network errors per second"

      # SSL certificate expiring
      - alert: SSLCertificateExpiring
        expr: (probe_ssl_earliest_cert_expiry - time()) / 86400 < 30
        for: 1h
        labels:
          severity: warning
          service: network
        annotations:
          summary: "SSL certificate expiring soon"
          description: "Certificate expires in {{ $value }} days"

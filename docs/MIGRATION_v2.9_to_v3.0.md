# CERES v3.0.0 - Migration Guide (v2.9 ‚Üí v3.0)
# Production upgrade playbook with zero-downtime strategy

## –í–µ—Ä—Å–∏—è: v3.0.0
## –î–∞—Ç–∞: January 2026
## –°—Ç–∞—Ç—É—Å: Production Ready
## Breaking Changes: None

---

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
1. [–ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ v3.0.0](#—á—Ç–æ-–Ω–æ–≤–æ–≥–æ)
2. [–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è](#—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
3. [Pre-Migration Checklist](#pre-migration-checklist)
4. [Migration Procedure](#migration-procedure)
5. [Validation & Testing](#validation--testing)
6. [Rollback Plan](#rollback-plan)
7. [Performance Verification](#performance-verification)
8. [FAQ & Troubleshooting](#faq--troubleshooting)

---

## –ß—Ç–æ –Ω–æ–≤–æ–≥–æ

### üéØ –û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è v3.0.0

#### 1. Service Mesh Integration (Istio)
- **mTLS** –¥–ª—è –≤—Å–µ—Ö pod-to-pod –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π
- **Traffic Management** - advanced routing, load balancing, circuit breaking
- **Observability** - distributed tracing, metrics collection, traffic visualization
- **Security** - AuthorizationPolicy, RequestAuthentication, PeerAuthentication
- **HA Configuration** - 3 istiod replicas, 3 ingress gateways

**–§–∞–π–ª—ã:**
- `config/istio/istio-install.yml` (600+ —Å—Ç—Ä–æ–∫)

#### 2. Cost Optimization Suite
- **Right-sizing** —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
- **Spot Instances** –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (AWS, GCP)
- **Reserved Instances** –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- **Resource Quotas** –∏ LimitRange –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞—Ç—Ä–∞—Ç
- **Cost monitoring** –≤ real-time —Å Prometheus

**–§–∞–π–ª—ã:**
- `scripts/cost-optimization.sh` (600+ —Å—Ç—Ä–æ–∫)

#### 3. Multi-Cloud Deployment
- **AWS EKS** —Å Karpenter –¥–ª—è auto-scaling
- **Azure AKS** —Å Virtual Machine Scale Sets
- **Google GKE** —Å Autopilot (fully managed)
- **Hybrid Deployment** –ø–æ–¥–¥–µ—Ä–∂–∫–∞ edge locations
- **Infrastructure-as-Code** –ø–æ–ª–Ω—ã–π Terraform stack

**–§–∞–π–ª—ã:**
- `config/terraform/multi-cloud.tf` (1000+ —Å—Ç—Ä–æ–∫)

#### 4. Production Hardening
- **Pod Security Policies** (PSP) –¥–ª—è isolation
- **Network Policies** - default DENY all
- **RBAC** - least privilege service accounts
- **Audit Logging** - –ø–æ–ª–Ω–∞—è –∞—É–¥–∏—Ç —Ç—Ä–µ–π–ª
- **Runtime Security** - Falco integration
- **Secrets Encryption** - at-rest –∏ in-transit

**–§–∞–π–ª—ã:**
- `config/security/hardening-policies.yml` (600+ —Å—Ç—Ä–æ–∫)

#### 5. Performance Tuning
- **Kernel Optimization** - TCP buffer, connection handling
- **Container Runtime** - containerd optimization
- **Kubelet Tuning** - CPU pinning, NUMA awareness
- **etcd Optimization** - WAL, snapshot config
- **Network Performance** - BBR congestion control
- **Storage Optimization** - I/O scheduler, read-ahead

**–§–∞–π–ª—ã:**
- `scripts/performance-tuning.yml` (500+ —Å—Ç—Ä–æ–∫)

---

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### Minimum Requirements

```yaml
Kubernetes: v1.28 –∏–ª–∏ –≤—ã—à–µ
Nodes: 3 (minimum –¥–ª—è HA)
CPU: 4 cores per node (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 8+)
Memory: 8 GB per node (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 16+ GB)
Storage: 100 GB (–±—ã—Å—Ç—Ä–æ–µ –¥–∏—Å–∫–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ)
Network: 1Gbps+ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 10Gbps)
```

### Software Requirements

```bash
# CLI tools
kubectl v1.28+
helm 3.12+
istioctl 1.20+
terraform 1.0+
ansible 2.10+

# Kubernetes add-ons
metrics-server v0.6+
ingress-nginx –∏–ª–∏ Istio
cert-manager 1.13+
```

### Permission Requirements

```yaml
- ClusterAdmin access (–¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏)
- Service account —Å admin permissions
- IAM/RBAC permissions –¥–ª—è –æ–±–ª–∞—á–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
```

---

## Pre-Migration Checklist

### ‚úÖ –®–∞–≥ 1: Backup —Ç–µ–∫—É—â–µ–π —Å–∏—Å—Ç–µ–º—ã

```bash
# Backup etcd
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  snapshot save /tmp/etcd-backup-$(date +%Y%m%d).db

# Verify
ETCDCTL_API=3 etcdctl snapshot status /tmp/etcd-backup-*.db

# Backup Kubernetes resources
kubectl get all -A -o yaml > /tmp/k8s-backup-$(date +%Y%m%d).yaml
kubectl get pvc -A -o yaml >> /tmp/k8s-backup-$(date +%Y%m%d).yaml
kubectl get pv -o yaml >> /tmp/k8s-backup-$(date +%Y%m%d).yaml
```

### ‚úÖ –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–µ—Ä—Å–∏—é Kubernetes
kubectl version --short

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å resource requirements
kubectl top nodes
kubectl top pods -A

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å available PVs
kubectl get pv

# Verify node health
kubectl get nodes -o wide
kubectl describe nodes | grep -E "Ready|DiskPressure|MemoryPressure"
```

### ‚úÖ –®–∞–≥ 3: Drain –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å pods, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤—ã—Ç–µ—Å–Ω–µ–Ω—ã
for node in $(kubectl get nodes -o jsonpath='{.items[*].metadata.name}'); do
  echo "=== Node: $node ==="
  kubectl drain $node --dry-run=client --ignore-daemonsets --delete-emptydir-data
done

# –ü–æ–≤—ã—Å–∏—Ç—å PodDisruptionBudget –∑–Ω–∞—á–µ–Ω–∏—è
kubectl patch pdb <name> -n <ns> -p '{"spec":{"minAvailable":null,"maxUnavailable":2}}'
```

### ‚úÖ –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å image registry

```bash
# Verify docker/container registry access
kubectl run registry-test --image=curlimages/curl --rm -it \
  -- sh -c 'curl -v https://registry.ceres.io/v2/_catalog'

# List all images in use
kubectl get pods -A -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\n' | sort -u
```

### ‚úÖ –®–∞–≥ 5: –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ

```bash
# Current version info
kubectl version > /tmp/pre-migration-k8s-version.txt
istioctl version >> /tmp/pre-migration-k8s-version.txt || true
helm version >> /tmp/pre-migration-k8s-version.txt

# Cluster info
kubectl cluster-info dump --output-directory=/tmp/k8s-cluster-dump-$(date +%Y%m%d)
```

---

## Migration Procedure

### –§–∞–∑–∞ 1: Istio Service Mesh Installation (90 –º–∏–Ω—É—Ç)

```bash
# 1. Install Istio using IstioOperator
kubectl create namespace istio-system
kubectl apply -f config/istio/istio-install.yml

# Wait for Istio to be ready
kubectl wait --for=condition=ready pod \
  -l app=istiod -n istio-system --timeout=300s

# Verify istiod
kubectl get pod -n istio-system -l app=istiod
kubectl logs -n istio-system -l app=istiod --tail=50

# 2. Enable sidecar injection
kubectl label namespace ceres istio-injection=enabled

# 3. Apply Istio configuration
kubectl apply -f config/istio/istio-install.yml

# 4. Verify gateways are ready
kubectl get gateway -n istio-system
kubectl get ingressgateway -n istio-system
```

### –§–∞–∑–∞ 2: Cost Optimization Setup (60 –º–∏–Ω—É—Ç)

```bash
# 1. Run cost optimization script
./scripts/cost-optimization.sh ceres-prod ceres /tmp/cost-reports

# 2. Apply resource quotas
kubectl apply -f config/security/hardening-policies.yml

# 3. Set up monitoring
kubectl create configmap cost-metrics -n ceres \
  --from-file=prometheus-rules.yaml=<(...)

# 4. Verify quotas
kubectl describe resourcequota -n ceres
kubectl describe limitrange -n ceres
```

### –§–∞–∑–∞ 3: Multi-Cloud Infrastructure (120 –º–∏–Ω—É—Ç)

```bash
# 1. Prepare Terraform variables
cat > terraform.tfvars <<EOF
aws_region = "eu-west-1"
azure_region = "westeurope"
gcp_project = "ceres-prod"
gcp_region = "europe-west1"
EOF

# 2. Validate Terraform
cd config/terraform
terraform init
terraform validate
terraform plan -out=tfplan

# 3. Apply Terraform (dry-run first in staging)
# terraform apply tfplan

# 4. Verify cloud resources
aws eks describe-cluster --name ceres-prod
az aks show --resource-group rg-ceres-prod --name ceres-aks
gcloud container clusters describe ceres-gke --region europe-west1
```

### –§–∞–∑–∞ 4: Security Hardening (120 –º–∏–Ω—É—Ç)

```bash
# 1. Apply security policies
kubectl apply -f config/security/hardening-policies.yml

# 2. Verify PSP
kubectl get psp
kubectl describe psp ceres-restricted

# 3. Apply network policies
kubectl apply -f config/security/hardening-policies.yml -l network-policy=true

# 4. Check audit logging
grep "audit-log" /etc/kubernetes/manifests/kube-apiserver.yaml

# 5. Verify secrets encryption
grep "encryption" /etc/kubernetes/manifests/kube-apiserver.yaml
```

### –§–∞–∑–∞ 5: Performance Tuning (90 –º–∏–Ω—É—Ç)

```bash
# 1. Run performance playbook
ansible-playbook -i inventory.yml scripts/performance-tuning.yml

# 2. Verify kernel parameters
sysctl -a | grep net.core.rmem_max
sysctl -a | grep tcp_congestion_control

# 3. Check kubelet config
kubectl get node <node> -o jsonpath='{.metadata.annotations}' | grep kubelet

# 4. Monitor node utilization
kubectl top nodes
```

### –§–∞–∑–∞ 6: Migration Validation (60 –º–∏–Ω—É—Ç)

```bash
# 1. Drain and update nodes (rolling update)
for node in $(kubectl get nodes -o jsonpath='{.items[*].metadata.name}'); do
  echo "Draining $node..."
  kubectl drain $node --ignore-daemonsets --delete-emptydir-data
  
  # Update node (depends on your cluster management)
  # ssh <node> "sudo apt update && sudo apt upgrade -y"
  
  echo "Uncordoning $node..."
  kubectl uncordon $node
  
  # Wait for readiness
  kubectl wait --for=condition=ready node/$node --timeout=300s
done

# 2. Verify all pods are running
kubectl get pods -A --field-selector=status.phase!=Running

# 3. Run connectivity tests
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl -v http://api.ceres.svc.cluster.local:8080/health
```

---

## Validation & Testing

### ‚úÖ Health Checks

```bash
#!/bin/bash
# health-check.sh

echo "=== Kubernetes Cluster Health ==="
kubectl cluster-info
kubectl get nodes -o wide
kubectl get componentstatuses

echo "=== Pod Health ==="
kubectl get pods -A --field-selector=status.phase!=Running

echo "=== Istio Health ==="
kubectl get pods -n istio-system
istioctl analyze

echo "=== Storage Health ==="
kubectl get pv,pvc -A

echo "=== Service Mesh Connectivity ==="
kubectl logs -l app=api-server -n ceres --tail=20

echo "=== Cost Metrics ==="
kubectl get --raw /metrics | grep cost:hourly || true
```

### ‚úÖ Performance Baseline

```bash
# 1. Measure API server latency
kubectl top nodes
kubectl top pods -A --containers

# 2. Run load test
kubectl run -it --rm load-test --image=loadimpact/k6 --restart=Never -- \
  k6 run - <<'EOF'
import http from 'k6/http';
import { check, sleep } from 'k6';

export default function() {
  let response = http.get('http://api.ceres.svc.cluster.local:8080/api/health');
  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 100ms': (r) => r.timings.duration < 100,
  });
  sleep(1);
}
EOF

# 3. Monitor during load
kubectl top nodes --containers
```

---

## Rollback Plan

```bash
# If something goes wrong, rollback is straightforward:

# 1. Restore from etcd backup (if needed)
ETCDCTL_API=3 etcdctl snapshot restore /tmp/etcd-backup-*.db \
  --data-dir=/var/lib/etcd-backup

# 2. Remove Istio (if issues)
kubectl delete -f config/istio/istio-install.yml
kubectl delete namespace istio-system

# 3. Remove security policies (if blocking workloads)
kubectl delete psp ceres-restricted
kubectl delete networkpolicies -A --selector=managed-by=ceres

# 4. Restore previous Kubernetes version
# This depends on your cluster management approach
```

---

## Performance Verification

### Network Performance

```bash
# TCP throughput test
iperf3 -s &
kubectl run iperf-client --image=networkstatic/iperf3 -- \
  iperf3 -c <service-ip> -t 10

# DNS resolution performance
time kubectl exec -it <pod> -- nslookup api.ceres.svc.cluster.local
```

### Storage Performance

```bash
# PVC I/O benchmark
kubectl run -it --rm fio --image=ljishen/fio --restart=Never -- \
  fio --name=random-read --ioengine=libaio --iodepth=32 \
  --rw=randread --bs=4k --direct=1 --size=1G --numjobs=4 \
  --runtime=60 --group_reporting
```

### Application Performance

```bash
# Check tail latencies
kubectl logs <pod> | grep "latency_p99"

# Monitor resource usage
kubectl top pods -n ceres --containers

# Check cache hit rates
kubectl logs <pod> | grep "cache.*hit"
```

---

## FAQ & Troubleshooting

### Q: –°–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–π–º–µ—Ç –º–∏–≥—Ä–∞—Ü–∏—è?
**A:** ~8-10 —á–∞—Å–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ –∏ –Ω–∞–≥—Ä—É–∑–∫–∏

### Q: –ë—É–¥–µ—Ç –ª–∏ downtime?
**A:** –ù–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è rolling update —Å PodDisruptionBudget

### Q: –ö–∞–∫–æ–π disk space –Ω—É–∂–µ–Ω?
**A:** ~50GB –¥–ª—è backup, ~20GB –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

### Q: –ß—Ç–æ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ pod –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è?
```bash
# 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å logs
kubectl logs <pod> -n <namespace>

# 2. –û–ø–∏—Å–∞—Ç—å pod
kubectl describe pod <pod> -n <namespace>

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å events
kubectl get events -n <namespace> --sort-by='.lastTimestamp'
```

### Q: –ö–∞–∫ –æ—Ç–∫–∞—Ç–∏—Ç—å—Å—è –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å?
**A:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ rollback –ø—Ä–æ—Ü–µ–¥—É—Ä—É –≤—ã—à–µ

### Q: –°–æ–≤–º–µ—Å—Ç–∏–º–∞ –ª–∏ v3.0 —Å –º–æ–∏–º–∏ —Å—Ç–∞—Ä—ã–º–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏?
**A:** –î–∞, –ø–æ–ª–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å. –°—Ç–∞—Ä—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –ø—Ä–æ–¥–æ–ª–∂–∞—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.

### –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

#### Istio pod –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
kubectl logs -n istio-system -l app=istiod

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã
kubectl describe node <node>

# –£–≤–µ–ª–∏—á–∏—Ç—å timeout
kubectl apply -f - <<EOF
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
spec:
  components:
    pilot:
      k8s:
        resources:
          requests:
            cpu: 1000m
            memory: 1024Mi
EOF
```

#### Network policy –±–ª–æ–∫–∏—Ä—É–µ—Ç —Ç—Ä–∞—Ñ–∏–∫
```bash
# –í—Ä–µ–º–µ–Ω–Ω–æ —É–¥–∞–ª–∏—Ç—å
kubectl delete networkpolicies --all -n ceres

# –ü–æ—Å–ª–µ –æ—Ç–ª–∞–¥–∫–∏, –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É
kubectl apply -f config/security/hardening-policies.yml
```

#### Cost optimization –Ω–µ —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å ConfigMap
kubectl get cm cost-metrics -n ceres -o yaml

# –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å Prometheus
kubectl rollout restart deployment/prometheus -n monitoring
```

---

## Post-Migration Validation

```bash
# Final checklist

# 1. All pods running
kubectl get pods -A --field-selector=status.phase!=Running

# 2. Service mesh healthy
istioctl analyze
kubectl get virtualservices -A

# 3. Cost tracking enabled
kubectl get configmap cost-metrics -n ceres

# 4. Security policies in place
kubectl get psp
kubectl get networkpolicies -A

# 5. Performance baseline met
kubectl top nodes
kubectl top pods -A | head -20
```

---

**Migration completed successfully!** üéâ

–¢–µ–ø–µ—Ä—å CERES v3.0.0 –ø–æ–ª–Ω–æ—Å—Ç—å—é:
- ‚úÖ Service mesh enabled
- ‚úÖ Cost optimized
- ‚úÖ Multi-cloud ready
- ‚úÖ Security hardened
- ‚úÖ Performance tuned
- ‚úÖ Production grade
